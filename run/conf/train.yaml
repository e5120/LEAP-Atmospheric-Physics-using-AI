hydra:
  job:
    name: train
    chdir: true
  run:
    dir: ${dir.model_dir}/${exp_name}/${dir_name}
  sweep:
    dir: ${dir.model_dir}/${exp_name}
    subdir: run${hydra.job.num}

defaults:
  - _self_
  - dir: local
  - dataset: single_dataset
  - model: ffn_model
  - optimizer: adamw
  - scheduler: reduce_lr

dir_name: single
exp_name: dummy
stage: train
chunk_size: 10
val_chunk_size: 3
batch_size: 4096
seed: 42
num_workers: 5
benchmark: False
logger: False

trainer:
  max_epochs: 100
  min_epochs: 200
  enable_progress_bar: True
  accelerator: auto
  precision: "16-mixed"
  # precision: 64
  gradient_clip_val: ~
  accumulate_grad_batches: 1
  reload_dataloaders_every_n_epochs: 1
  devices: [0]

early_stopping:
  monitor: "val_r2"
  mode: "max"
  patience: 3

model_checkpoint:
  save_weights_only: True
  monitor: "val_r2"
  mode: "max"
  dirpath: True
  save_top_k: 1
  verbose: 1

used_input_cols: ~
used_output_cols: ~
# used_input_cols:
#   - state_t
#   - state_q0001
#   - state_q0002
#   - state_q0003
#   - state_u
#   - state_v
#   - state_ps
#   - pbuf_LHFLX
#   - pbuf_SHFLX
#   - cam_in_LWUP
# used_output_cols:
#   - ptend_t
unused_input_cols: ~
unused_output_cols: ~
